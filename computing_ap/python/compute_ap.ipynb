{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from average_precision import Box, evaluate_detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ground truth bounding boxes\n",
    "G = pd.read_csv(\n",
    "    'ground_truth_boxes.csv', header=None, \n",
    "    names=['img_name', 'label', 'x', 'y', 'w', 'h']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# detected(predicted) bounding boxes\n",
    "D = pd.read_csv(\n",
    "    'predictions.csv', header=None,\n",
    "    names=['img_name', 'label', 'confidence', 'x', 'y', 'w', 'h']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pandas_to_dict(dataframe, sort_by_area=False):\n",
    "    \n",
    "    # bounding boxes of different labels are separated\n",
    "    boxes_per_label = {}\n",
    "    unique_labels = dataframe['label'].unique()\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        \n",
    "        # bounding boxes on different images are separated\n",
    "        boxes_per_img = {}\n",
    "        \n",
    "        # iterate over all boxes of a particular label\n",
    "        for i, row in dataframe.loc[dataframe['label'] == label].iterrows():\n",
    "            image_name = row['img_name']\n",
    "            if image_name in boxes_per_img:\n",
    "                boxes_per_img[image_name] += [Box(row)]\n",
    "            else:\n",
    "                boxes_per_img[image_name] = [Box(row)]\n",
    "        \n",
    "        if sort_by_area:\n",
    "            # for each image we sort bounding boxes by area\n",
    "            for img in boxes_per_img:\n",
    "                boxes_per_img[img].sort(key=lambda b: b.area, reverse=True)\n",
    "        \n",
    "        boxes_per_label[label] = boxes_per_img\n",
    "    \n",
    "    return boxes_per_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.03 s, sys: 8 ms, total: 3.04 s\n",
      "Wall time: 3.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gt_boxes_by_label = pandas_to_dict(G, sort_by_area=True)\n",
    "pred_boxes_by_label = pandas_to_dict(D)\n",
    "# so, now we have two dictionary of dictionaries:\n",
    "# label -> (image -> bounding boxes for this label and this image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute average precision for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 60 ms, sys: 0 ns, total: 60 ms\n",
      "Wall time: 61.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "APs = []\n",
    "for label in gt_boxes_by_label:\n",
    "    gt_boxes_by_img = gt_boxes_by_label[label]\n",
    "    pred_boxes_by_img = pred_boxes_by_label[label]\n",
    "    ap = evaluate_detector(gt_boxes_by_img, pred_boxes_by_img)\n",
    "    APs += [(label, ap)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' person', 0.5879933675211664),\n",
       " (' car', 0.6727775922888186),\n",
       " (' bus', 1.0),\n",
       " (' bicycle', 0.2683673469387755)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "APs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from average_precision import iou, compute_ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_detector_ver2(ground_truth_boxes_by_img, detected_boxes_by_img):\n",
    "    \n",
    "    precision, recall = [], []\n",
    "    # increase number of thresholds to get more accurate AP estimation\n",
    "    thresholds = [0.1*i for i in reversed(range(0, 10))]\n",
    "    \n",
    "    for confidence_threshold in thresholds:\n",
    "        \n",
    "        TP, FP, FN = 0, 0, 0\n",
    "        \n",
    "        for img in ground_truth_boxes_by_img:\n",
    "            \n",
    "            ground_truth_boxes = ground_truth_boxes_by_img[img]\n",
    "            detected_boxes = list(detected_boxes_by_img[img])  # copy\n",
    "            \n",
    "            detected_boxes = [\n",
    "                b for b in detected_boxes \n",
    "                if b.confidence >= confidence_threshold\n",
    "            ]\n",
    "            \n",
    "            for box in ground_truth_boxes:\n",
    "                matched = [b for b in detected_boxes if iou(box, b) > 0.5]\n",
    "                if len(matched) > 0:\n",
    "                    matched.sort(key=lambda b: b.confidence, reverse=True)\n",
    "                    detected_boxes.remove(matched[0])\n",
    "                    TP += 1\n",
    "                else:\n",
    "                    FN += 1\n",
    "            \n",
    "            FP += len(detected_boxes)\n",
    "        \n",
    "        # also consider images without gt boxes but with predictions\n",
    "        FP += sum([\n",
    "            len([b for b in detected_boxes_by_img[img] \n",
    "                 if b.confidence >= confidence_threshold]) \n",
    "            for img in detected_boxes_by_img \n",
    "            if not img in ground_truth_boxes_by_img\n",
    "        ])\n",
    "        \n",
    "        if (TP + FP) != 0:\n",
    "            precision += [float(TP)/float(TP + FP)]\n",
    "            recall += [float(TP)/float(TP + FN)]\n",
    "            print('{0:.1f} {1:.3f} {2:.3f}'.format(\n",
    "                confidence_threshold, precision[-1], recall[-1]\n",
    "            ))\n",
    "        \n",
    "    return compute_ap(precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label = person\n",
      "0.9 1.000 0.009\n",
      "0.8 1.000 0.094\n",
      "0.7 1.000 0.197\n",
      "0.6 0.972 0.299\n",
      "0.5 0.939 0.393\n",
      "0.4 0.883 0.453\n",
      "0.3 0.756 0.530\n",
      "0.2 0.578 0.573\n",
      "0.1 0.405 0.641\n",
      "0.0 0.009 0.735\n",
      "AP = 0.549 \n",
      "\n",
      "label = car\n",
      "0.8 1.000 0.091\n",
      "0.7 1.000 0.182\n",
      "0.6 0.923 0.364\n",
      "0.5 0.842 0.485\n",
      "0.4 0.810 0.515\n",
      "0.3 0.786 0.667\n",
      "0.2 0.686 0.727\n",
      "0.1 0.545 0.727\n",
      "0.0 0.008 0.758\n",
      "AP = 0.637 \n",
      "\n",
      "label = bus\n",
      "0.8 1.000 0.250\n",
      "0.7 1.000 0.500\n",
      "0.6 1.000 0.500\n",
      "0.5 1.000 0.500\n",
      "0.4 1.000 0.500\n",
      "0.3 1.000 1.000\n",
      "0.2 1.000 1.000\n",
      "0.1 0.800 1.000\n",
      "0.0 0.005 1.000\n",
      "AP = 1.000 \n",
      "\n",
      "label = bicycle\n",
      "0.8 1.000 0.143\n",
      "0.7 1.000 0.214\n",
      "0.6 1.000 0.214\n",
      "0.5 1.000 0.214\n",
      "0.4 1.000 0.214\n",
      "0.3 1.000 0.214\n",
      "0.2 0.750 0.214\n",
      "0.1 0.600 0.214\n",
      "0.0 0.007 0.357\n",
      "AP = 0.215 \n",
      "\n",
      "CPU times: user 68 ms, sys: 4 ms, total: 72 ms\n",
      "Wall time: 69.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for label in gt_boxes_by_label:\n",
    "    print('label =' + label)\n",
    "    gt_boxes_by_img = gt_boxes_by_label[label]\n",
    "    pred_boxes_by_img = pred_boxes_by_label[label]\n",
    "    print('AP = {:.3f}'.format(\n",
    "        evaluate_detector_ver2(gt_boxes_by_img, pred_boxes_by_img)\n",
    "    ), '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
